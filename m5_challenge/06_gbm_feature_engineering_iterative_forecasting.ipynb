{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Running Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'full_dataset = True' to use the full data set. If 'full_dataset = True', then a data set containing only data one year of the hobbies sales in TX2. \n",
    "- 'save_results = True' to save the dataframe in m5_challenge\\data\\feature_engineering\\\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:10:23.664711Z",
     "start_time": "2020-05-11T13:10:23.661756Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = True\n",
    "save_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:10:24.601295Z",
     "start_time": "2020-05-11T13:10:23.666714Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:17:45.421485Z",
     "start_time": "2020-05-11T13:10:24.602281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\domin\\anaconda3\\envs\\predicting-sales-data\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (14,15,16,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sale</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181085</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181086</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181087</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181088</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181089</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "0         HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1         HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2         HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3         HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4         HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "59181085    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "59181086    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "59181087    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "59181088    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "59181089    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "         store_id state_id       d  sale        date  wm_yr_wk  ...  year  \\\n",
       "0            CA_1       CA     d_1   0.0  2011-01-29     11101  ...  2011   \n",
       "1            CA_1       CA     d_1   0.0  2011-01-29     11101  ...  2011   \n",
       "2            CA_1       CA     d_1   0.0  2011-01-29     11101  ...  2011   \n",
       "3            CA_1       CA     d_1   0.0  2011-01-29     11101  ...  2011   \n",
       "4            CA_1       CA     d_1   0.0  2011-01-29     11101  ...  2011   \n",
       "59181085     WI_3       WI  d_1941   NaN  2016-05-22     11617  ...  2016   \n",
       "59181086     WI_3       WI  d_1941   NaN  2016-05-22     11617  ...  2016   \n",
       "59181087     WI_3       WI  d_1941   NaN  2016-05-22     11617  ...  2016   \n",
       "59181088     WI_3       WI  d_1941   NaN  2016-05-22     11617  ...  2016   \n",
       "59181089     WI_3       WI  d_1941   NaN  2016-05-22     11617  ...  2016   \n",
       "\n",
       "          event_name_1  event_type_1  event_name_2 event_type_2 snap_CA  \\\n",
       "0                  NaN           NaN           NaN          NaN       0   \n",
       "1                  NaN           NaN           NaN          NaN       0   \n",
       "2                  NaN           NaN           NaN          NaN       0   \n",
       "3                  NaN           NaN           NaN          NaN       0   \n",
       "4                  NaN           NaN           NaN          NaN       0   \n",
       "59181085           NaN           NaN           NaN          NaN       0   \n",
       "59181086           NaN           NaN           NaN          NaN       0   \n",
       "59181087           NaN           NaN           NaN          NaN       0   \n",
       "59181088           NaN           NaN           NaN          NaN       0   \n",
       "59181089           NaN           NaN           NaN          NaN       0   \n",
       "\n",
       "         snap_TX snap_WI  sell_price   data_type  \n",
       "0              0       0         NaN       train  \n",
       "1              0       0         NaN       train  \n",
       "2              0       0         NaN       train  \n",
       "3              0       0         NaN       train  \n",
       "4              0       0         NaN       train  \n",
       "59181085       0       0        2.98  validation  \n",
       "59181086       0       0        2.48  validation  \n",
       "59181087       0       0        3.98  validation  \n",
       "59181088       0       0        1.28  validation  \n",
       "59181089       0       0        1.00  validation  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "submission = pd.read_csv(\n",
    "    f'{utils.get_m5_root_dir()}/data/input/sample_submission.csv')\n",
    "if full_dataset:\n",
    "    df_merged = pd.read_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/preprocessed/preprocessed_input_data.csv'\n",
    "    )\n",
    "else:\n",
    "    df_merged = pd.read_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/preprocessed/tx2_hobbies_1year.csv')\n",
    "\n",
    "# extract training and validation data (drop evaluation) since we are still in validation phase\n",
    "df_merged = df_merged.loc[df_merged['data_type'] != 'evaluation']\n",
    "\n",
    "# print top and bottom lines\n",
    "df_merged.head(5).append(df_merged.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:18:15.232372Z",
     "start_time": "2020-05-11T13:17:45.431444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage of decreased to 7732.21 Mb (28.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "# downcast numerical values to reduce mem usage\n",
    "df_merged = utils.reduce_mem_usage(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:29:59.573737Z",
     "start_time": "2020-05-11T13:18:15.233369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage of decreased to 3894.32 Mb (28.9% reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sale</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id  d  sale        date  wm_yr_wk  ...  year  event_name_1  \\\n",
       "0         0  0   0.0  2011-01-29     11101  ...  2011            13   \n",
       "1         0  0   0.0  2011-01-29     11101  ...  2011            13   \n",
       "2         0  0   0.0  2011-01-29     11101  ...  2011            13   \n",
       "3         0  0   0.0  2011-01-29     11101  ...  2011            13   \n",
       "4         0  0   0.0  2011-01-29     11101  ...  2011            13   \n",
       "\n",
       "   event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \\\n",
       "0             1             3             1        0        0        0   \n",
       "1             1             3             1        0        0        0   \n",
       "2             1             3             1        0        0        0   \n",
       "3             1             3             1        0        0        0   \n",
       "4             1             3             1        0        0        0   \n",
       "\n",
       "   sell_price  data_type  \n",
       "0         NaN      train  \n",
       "1         NaN      train  \n",
       "2         NaN      train  \n",
       "3         NaN      train  \n",
       "4         NaN      train  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical features to integers as the categorical values cause problems when using large datasets\n",
    "\n",
    "df_merged = utils.encode_categorical(df_merged, [\n",
    "    \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\",\n",
    "    \"event_type_1\", \"event_name_2\", \"event_type_2\", 'd'\n",
    "])\n",
    "\n",
    "df_merged.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:37:53.993689Z",
     "start_time": "2020-05-11T13:29:59.578725Z"
    }
   },
   "outputs": [],
   "source": [
    "# sales data\n",
    "\n",
    "# rolling mean and rolling std (weekly, monthly, quarterly, and half-year)\n",
    "df_merged['rolling_mean_t28_s7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7).rolling(28).mean())\n",
    "\n",
    "df_merged['rolling_mean_t28_s1'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(1).rolling(28).mean())\n",
    "\n",
    "df_merged['rolling_mean_t7_s7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7).rolling(7).mean())\n",
    "\n",
    "df_merged['rolling_mean_t7_s1'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(1).rolling(7).mean())\n",
    "\n",
    "df_merged['rolling_std_t28_s7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7).rolling(28).std())\n",
    "\n",
    "df_merged['rolling_kurt_t28_s7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7).rolling(28).kurt())\n",
    "\n",
    "df_merged['rolling_skew_t28_s7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7).rolling(30).skew())\n",
    "\n",
    "df_merged['lag_t28'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(28))\n",
    "\n",
    "df_merged['lag_t7'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(7))\n",
    "\n",
    "df_merged['lag_t1'] = df_merged.groupby(\n",
    "    ['id'])['sale'].transform(lambda x: x.shift(1))\n",
    "\n",
    "\n",
    "\n",
    "# product was up for sale if price is not zero\n",
    "df_merged['up_for_sale'] = np.where(df_merged['sell_price'].isna(), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:41:14.809856Z",
     "start_time": "2020-05-11T13:37:53.998645Z"
    }
   },
   "outputs": [],
   "source": [
    "# price data\n",
    "\n",
    "df_merged['lag_price_t1'] = df_merged.groupby(\n",
    "    ['id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "\n",
    "df_merged['rolling_price_max_t30'] = df_merged.groupby(\n",
    "    ['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(30).max())\n",
    "\n",
    "df_merged['price_change_t1'] = (df_merged['lag_price_t1'] -\n",
    "                                df_merged['sell_price']) / (\n",
    "                                    df_merged['lag_price_t1'])\n",
    "\n",
    "df_merged['price_change_t30'] = (df_merged['rolling_price_max_t30'] -\n",
    "                                 df_merged['sell_price']) / (\n",
    "                                     df_merged['rolling_price_max_t30'])\n",
    "\n",
    "df_merged['rolling_price_std_t28'] = df_merged.groupby(\n",
    "    ['id'])['sell_price'].transform(lambda x: x.rolling(28).std())\n",
    "\n",
    "df_merged.drop(['rolling_price_max_t30', 'lag_price_t1'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:41:39.565278Z",
     "start_time": "2020-05-11T13:41:14.849749Z"
    }
   },
   "outputs": [],
   "source": [
    "# date data\n",
    "\n",
    "# Saturday: wday = 1, Sunday: wday = 2\n",
    "df_merged[\"is_weekend\"] = df_merged[\"wday\"].isin([1, 2]).astype(np.int8)\n",
    "\n",
    "df_merged.loc[:, 'date'] = pd.to_datetime(df_merged['date'])\n",
    "df_merged['day'] = df_merged['date'].dt.day.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:41:39.598713Z",
     "start_time": "2020-05-11T13:41:39.574254Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: proper feature selection (e.g. random forrest)\n",
    "# for now: hardcoded list of features\n",
    "\n",
    "cat_features = [\n",
    "    'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month',\n",
    "    'day', 'is_weekend', 'wday', 'event_name_1', 'event_type_1',\n",
    "    'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI',\n",
    "    'up_for_sale'\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    'sell_price',\n",
    "    'rolling_mean_t28_s7', 'rolling_mean_t28_s1', 'rolling_mean_t7_s7',\n",
    "       'rolling_mean_t7_s1', 'rolling_std_t28_s7', 'rolling_kurt_t28_s7',\n",
    "       'rolling_skew_t28_s7', 'lag_t28', 'lag_t7', 'lag_t1',\n",
    "    'price_change_t1', 'price_change_t30', 'rolling_price_std_t28'\n",
    "]\n",
    "\n",
    "features = cat_features + num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:42:48.207180Z",
     "start_time": "2020-05-11T13:41:39.604212Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop first 180 days since they have missing caused by the feature engineering\n",
    "date_after_90_training_days = str(df_merged['date'].dt.date.min() +\n",
    "                                  pd.to_timedelta(180, unit='d'))\n",
    "df_merged = df_merged[df_merged['date'] > date_after_90_training_days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:47:35.190682Z",
     "start_time": "2020-05-11T13:42:48.261036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51954960, 32)\n",
      "(51954960,)\n",
      "(853720, 32)\n",
      "(853720,)\n",
      "(853720, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_merged[df_merged['date'] <= '2016-03-27'][features]\n",
    "y_train = df_merged[df_merged['date'] <= '2016-03-27']['sale']\n",
    "\n",
    "x_val = df_merged.loc[df_merged['data_type'] == 'train'].loc[\n",
    "    df_merged['date'] > '2016-03-27'][features]\n",
    "y_val = df_merged.loc[df_merged['data_type'] == 'train'].loc[\n",
    "    df_merged['date'] > '2016-03-27']['sale']\n",
    "\n",
    "x_pred = df_merged[(df_merged['data_type'] == 'validation')][features]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:47:35.235044Z",
     "start_time": "2020-05-11T13:47:35.203106Z"
    }
   },
   "outputs": [],
   "source": [
    "# create datasets\n",
    "train_data = lgb.Dataset(x_train,\n",
    "                         label=y_train,\n",
    "                         categorical_feature=cat_features,\n",
    "                         free_raw_data=False)\n",
    "validation_data = lgb.Dataset(x_val,\n",
    "                              label=y_val,\n",
    "                              categorical_feature=cat_features,\n",
    "                              free_raw_data=False,\n",
    "                              reference=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T14:26:33.175669Z",
     "start_time": "2020-05-11T13:47:35.239033Z"
    }
   },
   "outputs": [],
   "source": [
    "if save_results:\n",
    "\n",
    "    if full_dataset:\n",
    "        prefix = 'full_dataset_v2'\n",
    "    else:\n",
    "        prefix = 'subset_v2'\n",
    "\n",
    "    train_data.save_binary(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_train_lightgbm.bin'\n",
    "    )\n",
    "    validation_data.save_binary(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_validation_data_lightgbm.bin'\n",
    "    )\n",
    "\n",
    "    df_merged.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_df_merged.csv',\n",
    "        index=False)\n",
    "\n",
    "    x_train.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_x_train.csv',\n",
    "        index=False)\n",
    "    y_train.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_y_train.csv',\n",
    "        index=False)\n",
    "\n",
    "    x_val.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_x_val.csv',\n",
    "        index=False)\n",
    "    y_val.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_y_val.csv',\n",
    "        index=False)\n",
    "\n",
    "    x_pred.to_csv(\n",
    "        f'{utils.get_m5_root_dir()}/data/feature_engineering/{prefix}_x_pred.csv',\n",
    "        index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
